# è®­ç»ƒ vs æ¨ç†ï¼šä¸ºä»€ä¹ˆè®­ç»ƒæ—¶éœ€è¦å®Œæ•´æ¨¡å‹ï¼Ÿ

## æ ¸å¿ƒé—®é¢˜

**Q: è®­ç»ƒååªä¿å­˜ Adapterï¼ˆç±»ä¼¼ LoRAï¼‰ï¼Œä¸ºä»€ä¹ˆè®­ç»ƒæ—¶éœ€è¦åŠ è½½å®Œæ•´çš„ unlearned modelï¼Ÿ**

## å…³é”®ç†è§£

### Adapter ä¸æ˜¯ç‹¬ç«‹çš„æ¨¡å‹ï¼Œè€Œæ˜¯æ³¨å…¥åˆ°å®Œæ•´æ¨¡å‹ä¸­çš„

```
å®Œæ•´æ¨¡å‹ = åŸå§‹ Transformer + Adapterï¼ˆæ³¨å…¥ï¼‰
```

è®­ç»ƒæ—¶éœ€è¦å®Œæ•´æ¨¡å‹è¿›è¡Œ**å‰å‘ä¼ æ’­**ï¼Œè™½ç„¶åªæ›´æ–° Adapter å‚æ•°ã€‚

## è®­ç»ƒæ—¶çš„æµç¨‹

### 1. æ¨¡å‹åŠ è½½

```python
# åŠ è½½ä¸¤ä¸ªå®Œæ•´çš„æ¨¡å‹
pipe_original = CogVideoXPipeline.from_pretrained(...)  # å®Œæ•´æ¨¡å‹
pipe_unlearned = CogVideoXPipeline.from_pretrained(...)  # å®Œæ•´æ¨¡å‹

# åœ¨ unlearned æ¨¡å‹ä¸­æ³¨å…¥ Adapter
erasers = setup_cogvideo_adapter_eraser(
    model=pipe_unlearned.transformer,  # å®Œæ•´æ¨¡å‹
    eraser_rank=128
)
```

### 2. å‰å‘ä¼ æ’­ï¼ˆéœ€è¦å®Œæ•´æ¨¡å‹ï¼‰

```python
# è®¡ç®— unlearned æ¨¡å‹çš„è¾“å‡º
def model_wrapper_unlearned(x_t, t, cond):
    output = transformer_unlearned(  # å®Œæ•´æ¨¡å‹ + Adapter
        hidden_states,
        timestep=t,
        encoder_hidden_states=cond
    )
    return output

# è®¡ç®— original æ¨¡å‹çš„è¾“å‡ºï¼ˆç”¨äºå¯¹æ¯”ï¼‰
def model_wrapper_original(x_t, t, cond):
    with torch.no_grad():
        output = transformer_original(  # å®Œæ•´æ¨¡å‹ï¼ˆå†»ç»“ï¼‰
            hidden_states,
            timestep=t,
            encoder_hidden_states=cond
        )
    return output
```

### 3. å‰å‘ä¼ æ’­è¿‡ç¨‹

å½“è°ƒç”¨ `transformer_unlearned()` æ—¶ï¼š

```
è¾“å…¥: hidden_states
  â†“
Transformer Block 0:
  â”œâ”€ attn1 (åŸå§‹æ³¨æ„åŠ›)
  â”œâ”€ Adapter (æ³¨å…¥) â† åœ¨è¿™é‡Œä¿®æ”¹è¾“å‡º
  â””â”€ è¾“å‡º: hidden_states + adapter(hidden_states)
  â†“
Transformer Block 1:
  â”œâ”€ attn1 (åŸå§‹æ³¨æ„åŠ›)
  â”œâ”€ Adapter (æ³¨å…¥) â† åœ¨è¿™é‡Œä¿®æ”¹è¾“å‡º
  â””â”€ è¾“å‡º: hidden_states + adapter(hidden_states)
  â†“
...
Transformer Block 40:
  â”œâ”€ attn1 (åŸå§‹æ³¨æ„åŠ›)
  â”œâ”€ Adapter (æ³¨å…¥) â† åœ¨è¿™é‡Œä¿®æ”¹è¾“å‡º
  â””â”€ è¾“å‡º: hidden_states + adapter(hidden_states)
  â†“
æœ€ç»ˆè¾“å‡º
```

**å…³é”®ç‚¹**ï¼š
- æ¯ä¸€å±‚éƒ½éœ€è¦åŸå§‹ Transformer è®¡ç®—æ³¨æ„åŠ›
- Adapter åªæ˜¯ä¿®æ”¹è¾“å‡ºï¼ˆæ®‹å·®è¿æ¥ï¼‰
- **æ²¡æœ‰å®Œæ•´æ¨¡å‹ï¼Œæ— æ³•è¿›è¡Œå‰å‘ä¼ æ’­**

### 4. æŸå¤±è®¡ç®—

```python
# éœ€è¦ä¸¤ä¸ªæ¨¡å‹çš„è¾“å‡ºè¿›è¡Œå¯¹æ¯”
loss = loss_fn(
    model_original=model_wrapper_original,    # åŸå§‹æ¨¡å‹è¾“å‡º
    model_unlearned=model_wrapper_unlearned,  # å»å­¦ä¹ æ¨¡å‹è¾“å‡º
    ...
)
```

### 5. åå‘ä¼ æ’­ï¼ˆåªæ›´æ–° Adapterï¼‰

```python
# å†»ç»“åŸå§‹æ¨¡å‹å‚æ•°
for param in pipe_unlearned.transformer.parameters():
    param.requires_grad = False  # ä¸æ›´æ–°

# åªä¼˜åŒ– Adapter å‚æ•°
for eraser in erasers.values():
    for param in eraser.parameters():
        param.requires_grad = True  # åªæ›´æ–°è¿™ä¸ª

# åå‘ä¼ æ’­
loss.backward()  # åªè®¡ç®— Adapter çš„æ¢¯åº¦
optimizer.step()  # åªæ›´æ–° Adapter å‚æ•°
```

### 6. ä¿å­˜ï¼ˆåªä¿å­˜ Adapterï¼‰

```python
# åªä¿å­˜ Adapter æƒé‡ï¼Œä¸ä¿å­˜å®Œæ•´æ¨¡å‹
save_cogvideo_eraser_from_transformer(
    output_dir,
    pipe_unlearned.transformer
)
# ä¿å­˜çš„æ–‡ä»¶ï¼š
# - eraser_weights.pt (åªæœ‰ Adapter æƒé‡ï¼Œ~12.3M å‚æ•°)
# - eraser_config.json (é…ç½®ä¿¡æ¯)
```

## æ¨ç†æ—¶çš„æµç¨‹

### 1. åŠ è½½åŸå§‹æ¨¡å‹

```python
pipe = CogVideoXPipeline.from_pretrained(
    model_path,  # åŸå§‹æ¨¡å‹è·¯å¾„
    torch_dtype=torch.float16
)
```

### 2. æ³¨å…¥è®­ç»ƒå¥½çš„ Adapter

```python
# åŠ è½½ Adapter æƒé‡
eraser_ckpt = torch.load("eraser_weights.pt")
eraser_config = json.load("eraser_config.json")

# æ³¨å…¥åˆ°åŸå§‹æ¨¡å‹ä¸­
inject_eraser(
    transformer=pipe.transformer,
    eraser_ckpt=eraser_ckpt,
    eraser_rank=eraser_config['eraser_rank']
)
```

### 3. æ¨ç†

```python
# ç°åœ¨ pipe.transformer å·²ç»åŒ…å« Adapter
video = pipe(prompt="...")
```

## ä¸ºä»€ä¹ˆè®­ç»ƒæ—¶éœ€è¦å®Œæ•´æ¨¡å‹ï¼Ÿ

### åŸå›  1: å‰å‘ä¼ æ’­éœ€è¦å®Œæ•´æ¨¡å‹

Adapter ä¸æ˜¯ç‹¬ç«‹çš„æ¨¡å‹ï¼Œå®ƒéœ€è¦ï¼š
- åŸå§‹ Transformer è®¡ç®—æ³¨æ„åŠ›
- Adapter ä¿®æ”¹è¾“å‡ºï¼ˆæ®‹å·®è¿æ¥ï¼‰

```
output = transformer_block(hidden_states) + adapter(hidden_states)
         â†‘                        â†‘
    éœ€è¦å®Œæ•´æ¨¡å‹            éœ€è¦å®Œæ•´æ¨¡å‹ä½œä¸ºè¾“å…¥
```

### åŸå›  2: æŸå¤±è®¡ç®—éœ€è¦ä¸¤ä¸ªæ¨¡å‹çš„è¾“å‡º

```python
# Unlearning Loss: éœ€è¦ unlearned æ¨¡å‹çš„è¾“å‡º
v_unlearned = model_unlearned(x_t, t, cond_target)

# Preservation Loss: éœ€è¦ original æ¨¡å‹çš„è¾“å‡ºï¼ˆå¯¹æ¯”ï¼‰
v_original = model_original(x_t, t, cond_preserve)

loss = ||v_unlearned - v_negative||Â² + ||v_unlearned - v_original||Â²
```

### åŸå›  3: æ¿€æ´»å€¼éœ€è¦å®Œæ•´æ¨¡å‹

å‰å‘ä¼ æ’­æ—¶ï¼Œæ¯ä¸€å±‚çš„æ¿€æ´»å€¼éƒ½éœ€è¦å­˜å‚¨ï¼ˆç”¨äºåå‘ä¼ æ’­ï¼‰ï¼š
- Transformer çš„æ¿€æ´»å€¼ï¼š~100-150 GB
- Adapter çš„æ¿€æ´»å€¼ï¼šå¾ˆå°ï¼Œå¯ä»¥å¿½ç•¥

å³ä½¿åªæ›´æ–° Adapterï¼Œä¹Ÿéœ€è¦å­˜å‚¨å®Œæ•´æ¨¡å‹çš„æ¿€æ´»å€¼ã€‚

## æ˜¾å­˜å ç”¨å¯¹æ¯”

### è®­ç»ƒæ—¶ï¼ˆéœ€è¦å®Œæ•´æ¨¡å‹ï¼‰

| ç»„ä»¶ | æ˜¾å­˜ | è¯´æ˜ |
|------|------|------|
| Original Model | ~10 GB | å®Œæ•´æ¨¡å‹ï¼ˆå†»ç»“ï¼‰ |
| Unlearned Model | ~10 GB | å®Œæ•´æ¨¡å‹ï¼ˆå†»ç»“å‚æ•°ï¼Œä½†éœ€è¦å‰å‘ä¼ æ’­ï¼‰ |
| Adapter å‚æ•° | ~0.1 GB | å¾ˆå° |
| æ¿€æ´»å€¼ | ~100-150 GB | å®Œæ•´æ¨¡å‹çš„æ¿€æ´»å€¼ |
| **æ€»è®¡** | **~120-170 GB** | |

### æ¨ç†æ—¶ï¼ˆåªéœ€è¦ Adapter æƒé‡ï¼‰

| ç»„ä»¶ | æ˜¾å­˜ | è¯´æ˜ |
|------|------|------|
| åŸå§‹æ¨¡å‹ | ~10 GB | åŠ è½½ä¸€æ¬¡ |
| Adapter æƒé‡ | ~0.1 GB | æ³¨å…¥åˆ°æ¨¡å‹ä¸­ |
| æ¿€æ´»å€¼ | ~10-20 GB | æ¨ç†æ—¶ä¸éœ€è¦å­˜å‚¨æ‰€æœ‰æ¿€æ´»å€¼ |
| **æ€»è®¡** | **~20-30 GB** | |

## ç±»æ¯”ï¼šLoRA è®­ç»ƒ

### LoRA è®­ç»ƒä¹Ÿéœ€è¦å®Œæ•´æ¨¡å‹

```python
# LoRA è®­ç»ƒæ—¶
base_model = load_model()  # å®Œæ•´æ¨¡å‹
lora = LoRALayer()  # LoRA å±‚
# æ³¨å…¥
model = base_model + lora

# å‰å‘ä¼ æ’­
output = model(input)  # éœ€è¦å®Œæ•´æ¨¡å‹

# åå‘ä¼ æ’­
loss.backward()  # åªæ›´æ–° LoRA å‚æ•°

# ä¿å­˜
save_lora_weights()  # åªä¿å­˜ LoRA æƒé‡
```

**å…³é”®ç‚¹**ï¼šLoRA å’Œ Adapter ä¸€æ ·ï¼Œè®­ç»ƒæ—¶éƒ½éœ€è¦å®Œæ•´æ¨¡å‹è¿›è¡Œå‰å‘ä¼ æ’­ã€‚

## ä¼˜åŒ–ï¼šèƒ½å¦åªåŠ è½½ Adapterï¼Ÿ

### ç†è®ºä¸Šå¯ä»¥ï¼Œä½†å®ç°å¤æ‚

å¦‚æœåªåŠ è½½ Adapterï¼š
- âœ… æ˜¾å­˜èŠ‚çœï¼š~10 GBï¼ˆä¸éœ€è¦ unlearned modelï¼‰
- âŒ æ— æ³•è®¡ç®—æŸå¤±ï¼ˆéœ€è¦å®Œæ•´æ¨¡å‹è¾“å‡ºï¼‰
- âŒ æ— æ³•è¿›è¡Œå‰å‘ä¼ æ’­ï¼ˆAdapter ä¾èµ– Transformerï¼‰

### å®é™…æ–¹æ¡ˆï¼šä½¿ç”¨ CPU Offload

```bash
--use_cpu_offload
```

**æ•ˆæœ**ï¼š
- æ¨¡å‹å‚æ•°åŠ¨æ€åŠ è½½åˆ° GPU
- æ˜¾å­˜éœ€æ±‚ä» ~120-170 GB é™è‡³ ~15-25 GB
- **è¿™æ˜¯æœ€å®ç”¨çš„ä¼˜åŒ–æ–¹æ¡ˆ**

## æ€»ç»“

### ä¸ºä»€ä¹ˆè®­ç»ƒæ—¶éœ€è¦å®Œæ•´ unlearned modelï¼Ÿ

1. âœ… **å‰å‘ä¼ æ’­éœ€è¦**ï¼šAdapter ä¸æ˜¯ç‹¬ç«‹æ¨¡å‹ï¼Œéœ€è¦å®Œæ•´ Transformer è®¡ç®—
2. âœ… **æŸå¤±è®¡ç®—éœ€è¦**ï¼šéœ€è¦ unlearned æ¨¡å‹çš„å®Œæ•´è¾“å‡º
3. âœ… **æ¿€æ´»å€¼éœ€è¦**ï¼šåå‘ä¼ æ’­éœ€è¦å­˜å‚¨å®Œæ•´æ¨¡å‹çš„æ¿€æ´»å€¼

### è®­ç»ƒåä¿å­˜ä»€ä¹ˆï¼Ÿ

- âœ… **åªä¿å­˜ Adapter æƒé‡**ï¼ˆ~12.3M å‚æ•°ï¼‰
- âŒ **ä¸ä¿å­˜å®Œæ•´æ¨¡å‹**ï¼ˆå¯ä»¥ä»åŸå§‹æ¨¡å‹åŠ è½½ï¼‰

### æ¨ç†æ—¶å¦‚ä½•ä½¿ç”¨ï¼Ÿ

1. åŠ è½½åŸå§‹æ¨¡å‹
2. æ³¨å…¥è®­ç»ƒå¥½çš„ Adapter æƒé‡
3. æ¨ç†

### æ˜¾å­˜ä¼˜åŒ–

- ğŸ¥‡ **CPU Offload**ï¼šæœ€æœ‰æ•ˆï¼ˆèŠ‚çœ ~85-90%ï¼‰
- ğŸ¥ˆ **FP16**ï¼šèŠ‚çœ ~50%
- ğŸ¥‰ **å‡å° Batch Size**ï¼šçº¿æ€§å‡å°‘æ¿€æ´»å€¼

**å…³é”®ç†è§£**ï¼šAdapter æ˜¯"ä¿®æ”¹å™¨"ï¼Œä¸æ˜¯"æ›¿ä»£å™¨"ã€‚è®­ç»ƒæ—¶éœ€è¦å®Œæ•´æ¨¡å‹æ¥"ä¿®æ”¹"ï¼Œä½†ä¿å­˜æ—¶åªéœ€è¦"ä¿®æ”¹å™¨"æœ¬èº«ã€‚

